{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Pacific dataviz Challenge 2025](#toc0_)\n",
    "**The data processing notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner Image](<img/Roméo_et_juliette.png> \"Roméo & Juliet play at the théâtre de la Cité in Oct.'25.\") <br>Roméo et Juliette *(théâtre de la Cité - October '25; Photography: Christophe Raynaud de Lage)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook converts the original Pacific Dataviz Challenge dataset: a (quirky) Excel export into cleaned CSV and JSON files suitable for a analysis and use as backend for web apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Pacific dataviz Challenge 2025](#toc1_)    \n",
    "  - [Genesis](#toc1_1_)    \n",
    "    - [Imports and configuration](#toc1_1_1_)    \n",
    "  - [Section 1 - Data consolidation and preparation](#toc1_2_)    \n",
    "    - [Looking for sentinels](#toc1_2_1_)    \n",
    "    - [Solid foundations: restructuring the data](#toc1_2_2_)    \n",
    "      - [Geographic insights](#toc1_2_2_1_)    \n",
    "    - [Mapping key domains](#toc1_2_3_)    \n",
    "    - [Enrich with an indicator summary](#toc1_2_4_)    \n",
    "    - [Generate a complete group×state×year grid and detect missing records](#toc1_2_5_)    \n",
    "      - [Investigate missing data](#toc1_2_5_1_)    \n",
    "  - [Section 2) The case of Group58 and Group18](#toc1_3_)    \n",
    "    - [Group 58 - Transform wide-format-data to a long-format](#toc1_3_1_)    \n",
    "    - [Group 18 - The case of inverse relationships](#toc1_3_2_)    \n",
    "  - [Section 3) Prevalence filtering](#toc1_4_)    \n",
    "  - [Section 4) Scaling raw values](#toc1_5_)    \n",
    "  - [Section 5) Additional features](#toc1_6_)    \n",
    "    - [Metrics for completeness and contributions/rankings](#toc1_6_1_)    \n",
    "    - [Interactive report about data quality](#toc1_6_2_)    \n",
    "    - [Export data to JSON](#toc1_6_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Genesis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) From a messy Excel spreadsheet:\n",
    "\n",
    "![Banner Image](<img/excel.png> \"Screenshot of an Excel spreadsheet.\")\n",
    "\n",
    "2) To neat, **exploitable** datasets:\n",
    "\n",
    "CSV sample:\n",
    "\n",
    "```csv\n",
    "Group_id,Year,class_name,class_num,indicator_summary,Subregion_code,Subregion_name,State_code,State_name,Raw_values,Scaled_Values,value_contribution_to_class,State_rank_per_class,pct_missing_values\n",
    "0,1,2022,Political Leadership and Regionalism,1,Total development aid,MEL,Melanesia,FJ,Fiji,561024940.0000,0.8507,0.0305,6,0.0000\n",
    "```\n",
    "\n",
    "JSON sample:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"group_id\": 1,\n",
    "        \"year\": 2022,\n",
    "        \"class_name\": \"Political Leadership and Regionalism\",\n",
    "        \"class_num\": 1,\n",
    "        \"indicator_summary\": \"Total development aid\",\n",
    "        \"subregion_code\": \"MEL\",\n",
    "        \"subregion_name\": \"Melanesia\",\n",
    "        \"state_code\": \"FJ\",\n",
    "        \"state_name\": \"Fiji\",\n",
    "        \"raw_values\": 561024940.0,\n",
    "        \"scaled_values\": 0.8506735359,\n",
    "        \"value_contribution_to_class\": 0.0305291251,\n",
    "        \"state_rank_per_class\": 6,\n",
    "        \"pct_missing_values\": 0.0\n",
    "    }\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Imports and configuration](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#%pip install pandas numpy ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Disable scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Section 1 - Data consolidation and preparation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The processing pipeline is nearly fully automated; the first manual step was preparing the original Excel file by removing layout elements before loading it into a dataframe and prevent repeated openpyxl crashes.\n",
    ">  The other manual intervention consist in enriching the dataset metadata with LLM-generated topic summaries [see this part](#enrich-with-an-indicator-summary).\n",
    "\n",
    "Let's have a look at the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>(DF_BP50) Blue Pacific 2050 (all)</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(FREQ) Frequency: (A) Annual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(EDUCATION) Education level</td>\n",
       "      <td>(EDUCATION) Education level</td>\n",
       "      <td>(EDUCATION) Education level</td>\n",
       "      <td>(_T) All education levels</td>\n",
       "      <td>(02) Pre-primary education</td>\n",
       "      <td>(1) Primary education</td>\n",
       "      <td>(2-3) Secondary education (lower and upper sec...</td>\n",
       "      <td>(2) Lower secondary education</td>\n",
       "      <td>(3) Upper secondary education</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(GEO_PICT) Pacific Island Countries and territ...</td>\n",
       "      <td>(TIME_PERIOD) Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(INDICATOR) Indicator: (DC_TRF_TOTL) Political...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  (DF_BP50) Blue Pacific 2050 (all)  \\\n",
       "0         NaN                       (FREQ) Frequency: (A) Annual   \n",
       "1         NaN                                                NaN   \n",
       "2         NaN                        (EDUCATION) Education level   \n",
       "3         NaN  (GEO_PICT) Pacific Island Countries and territ...   \n",
       "4         NaN  (INDICATOR) Indicator: (DC_TRF_TOTL) Political...   \n",
       "\n",
       "                    Unnamed: 2                   Unnamed: 3  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2  (EDUCATION) Education level  (EDUCATION) Education level   \n",
       "3           (TIME_PERIOD) Time                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "                  Unnamed: 4                  Unnamed: 5  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2  (_T) All education levels  (02) Pre-primary education   \n",
       "3                        NaN                         NaN   \n",
       "4                        NaN                         NaN   \n",
       "\n",
       "              Unnamed: 6                                         Unnamed: 7  \\\n",
       "0                    NaN                                                NaN   \n",
       "1                    NaN                                                NaN   \n",
       "2  (1) Primary education  (2-3) Secondary education (lower and upper sec...   \n",
       "3                    NaN                                                NaN   \n",
       "4                    NaN                                                NaN   \n",
       "\n",
       "                      Unnamed: 8                     Unnamed: 9 Unnamed: 10  \n",
       "0                            NaN                            NaN         NaN  \n",
       "1                            NaN                            NaN         NaN  \n",
       "2  (2) Lower secondary education  (3) Upper secondary education         NaN  \n",
       "3                            NaN                            NaN         NaN  \n",
       "4                            NaN                            NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/cleared_format_excel.xlsx', engine='openpyxl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not good. Erm.. This is.. bad! Data is poorly structured. It's time to achieve some wonders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Looking for sentinels](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) On a logical level, we use a \"group\" granularity where each group is a collection of records for multiple countries corresponding to a **unique** indicator.\n",
    "\n",
    "Have a look back at the spreadsheet above: one group example is, *\"total assistance for development, by recipent countries\".*\n",
    "\n",
    "2) The cell below is designed to organize and structure the data. Process a DataFrame to identify and group records based on predefined sentinel markers, such as `(INDICATOR)` and `(OCCUPATION)`. \n",
    "   - Have a look at the excel spreadsheet screenshot (again, yes! ;). **A grey cell** precedes each groups data and its composition is consistent: it always contains the same marker words.\n",
    "   -  The algorithm will jump from grey-cell-content to grey-cell-content and isolate the records between them as belonging to the same indicator **group**. \n",
    "\n",
    "> How? These markers identify distinct sections of data we need to isolate by iterating through the specified column, checking if rows start with these flags, and collects full sentinel texts into a buffer. When all markers of a group are found (meaning the group is complete), it logs the group and resets for the next. Finally, it assigns group IDs back to the DataFrame and exports the collected metadata to a JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentinel markers in order\n",
    "sentinels = [\n",
    "    \"(INDICATOR)\",\n",
    "    \"(OCCUPATION)\",\n",
    "    \"(COMPOSITE_BREAKDOWN)\",\n",
    "    \"(DISABILITY)\",\n",
    "]\n",
    "\n",
    "group_id = 0\n",
    "next_sentinel_idx = 0\n",
    "sentinel_buffer = {}\n",
    "groups_meta = []\n",
    "group_ids = []\n",
    "\n",
    "# Iterate over each row\n",
    "for idx, cell in df[\"(DF_BP50) Blue Pacific 2050 (all)\"].fillna(\"\").items():\n",
    "    text = cell.strip()\n",
    "\n",
    "    # Check if it starts with the next sentinel\n",
    "    if text.startswith(sentinels[next_sentinel_idx]):\n",
    "        # Record the full sentinel text\n",
    "        sentinel_buffer[next_sentinel_idx] = text\n",
    "\n",
    "        # Move to look for the next sentinel\n",
    "        next_sentinel_idx += 1\n",
    "\n",
    "        # If we have collected all 4, that completes one group\n",
    "        if next_sentinel_idx == len(sentinels):\n",
    "            group_id += 1\n",
    "            groups_meta.append({\n",
    "                \"group_number\": group_id,\n",
    "                \"sentinels\": [sentinel_buffer[i] for i in range(len(sentinels))]\n",
    "            })\n",
    "            # Reset for the next group\n",
    "            next_sentinel_idx = 0\n",
    "            sentinel_buffer.clear()\n",
    "\n",
    "    # Assign current group_id (0 if group not started yet)\n",
    "    group_ids.append(group_id)\n",
    "\n",
    "# Attach the group column\n",
    "df[\"Group_id\"] = group_ids\n",
    "\n",
    "json_out = json.dumps(groups_meta, indent=2)\n",
    "\n",
    "with open(\"data/groups_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Solid foundations: restructuring the data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the dataset computationally. A consistent tabular structure is needed.\n",
    "\n",
    "1) Clean the DataFrame by first dropping unnecessary columns. \n",
    "2) Then extract and convert the year from the `Unnamed: 2` column to an integer.\n",
    "3) Regional information: The original column (containing the regional data) is renamed for clarity as `RegionFull`. The code identifies state names by looking for lines that start with a bullet point `\"·\"` marker. It creates new columns for `Subregion` and `State` based on the content of `RegionFull`. States are linked to their preceding subregions, and the code extracts codes for both subregions and states while removing any extraneous characters.\n",
    "4)  Finally, filter the data into a new DataFrame, `df_data`, containing only relevant entries and columns. The result is a streamlined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Group_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Subregion_code</th>\n",
       "      <th>Subregion_name</th>\n",
       "      <th>State_code</th>\n",
       "      <th>State_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>561024940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>572455900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256630130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>SB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>183972650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>VU</td>\n",
       "      <td>Vanuatu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90657960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>MIC</td>\n",
       "      <td>Micronesia</td>\n",
       "      <td>KI</td>\n",
       "      <td>Kiribati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2024</td>\n",
       "      <td>POL</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>WS</td>\n",
       "      <td>Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.3300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2022</td>\n",
       "      <td>POL</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>TO</td>\n",
       "      <td>Tonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.3200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2024</td>\n",
       "      <td>POL</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>TO</td>\n",
       "      <td>Tonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.2300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2022</td>\n",
       "      <td>POL</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>TV</td>\n",
       "      <td>Tuvalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2024</td>\n",
       "      <td>POL</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>TV</td>\n",
       "      <td>Tuvalu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1246 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  \\\n",
       "9     561024940        NaN        NaN        NaN        NaN        NaN   \n",
       "10    572455900        NaN        NaN        NaN        NaN        NaN   \n",
       "11    256630130        NaN        NaN        NaN        NaN        NaN   \n",
       "12    183972650        NaN        NaN        NaN        NaN        NaN   \n",
       "14     90657960        NaN        NaN        NaN        NaN        NaN   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1970     0.3600        NaN        NaN        NaN        NaN        NaN   \n",
       "1971     0.3300        NaN        NaN        NaN        NaN        NaN   \n",
       "1972     0.3200        NaN        NaN        NaN        NaN        NaN   \n",
       "1973     0.2300        NaN        NaN        NaN        NaN        NaN   \n",
       "1974     0.1900        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "     Unnamed: 10  Group_id  Year Subregion_code Subregion_name State_code  \\\n",
       "9            NaN         1  2022            MEL      Melanesia         FJ   \n",
       "10           NaN         1  2022            MEL      Melanesia         PG   \n",
       "11           NaN         1  2022            MEL      Melanesia         SB   \n",
       "12           NaN         1  2022            MEL      Melanesia         VU   \n",
       "14           NaN         1  2022            MIC     Micronesia         KI   \n",
       "...          ...       ...   ...            ...            ...        ...   \n",
       "1970         NaN       112  2024            POL      Polynesia         WS   \n",
       "1971         NaN       112  2022            POL      Polynesia         TO   \n",
       "1972         NaN       112  2024            POL      Polynesia         TO   \n",
       "1973         NaN       112  2022            POL      Polynesia         TV   \n",
       "1974         NaN       112  2024            POL      Polynesia         TV   \n",
       "\n",
       "            State_name  \n",
       "9                 Fiji  \n",
       "10    Papua New Guinea  \n",
       "11     Solomon Islands  \n",
       "12             Vanuatu  \n",
       "14            Kiribati  \n",
       "...                ...  \n",
       "1970             Samoa  \n",
       "1971             Tonga  \n",
       "1972             Tonga  \n",
       "1973            Tuvalu  \n",
       "1974            Tuvalu  \n",
       "\n",
       "[1246 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Drop the unwanted columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 3'])\n",
    "\n",
    "# 2) Clean up the year‐column (formerly Unnamed: 2)\n",
    "# Remove the parentheses and cast to int.\n",
    "df['Year'] = df['Unnamed: 2'] \\\n",
    "    .astype(str) \\\n",
    "    .str.extract(r'\\)\\s*(\\d{4})') \\\n",
    "    .iloc[:, 0] \\\n",
    "    .astype('Int32')\n",
    "\n",
    "# 3) Split out subregions and states from the “(DF_BP50) Blue Pacific 2050 (all)” column\n",
    "#    We’ll call that column “RegionFull” for clarity\n",
    "df = df.rename(columns={'(DF_BP50) Blue Pacific 2050 (all)': 'RegionFull'})\n",
    "\n",
    "# Create empty columns\n",
    "df['Subregion'] = pd.NA\n",
    "df['State'] = pd.NA\n",
    "\n",
    "current_sub = None\n",
    "\n",
    "for idx, cell in df['RegionFull'].items():\n",
    "    if pd.isna(cell):\n",
    "        continue\n",
    "\n",
    "    s = str(cell).lstrip()\n",
    "    # Detect a state line by the leading dot “·”\n",
    "    if s.startswith('·'):\n",
    "        # It is a state\n",
    "        # remove the bullet and any extra whitespace:\n",
    "        name = s.lstrip('· ').strip()\n",
    "        df.at[idx, 'State'] = name\n",
    "        # carry down the most recent subregion if any\n",
    "        if current_sub:\n",
    "            df.at[idx, 'Subregion'] = current_sub\n",
    "\n",
    "    else:\n",
    "        # It is a subregion row\n",
    "        name = s.strip()\n",
    "        df.at[idx, 'Subregion'] = name\n",
    "        current_sub = name\n",
    "        # No state on the subregion row itself\n",
    "\n",
    "df[['Subregion_code', 'Subregion_name']\n",
    "   ] = df['Subregion'].str.split(' ', n=1, expand=True)\n",
    "df['Subregion_code'] = df['Subregion_code'].str.strip('()')\n",
    "\n",
    "df[['State_code', 'State_name']] = df['State'].str.split(' ', n=1, expand=True)\n",
    "df['State_code'] = df['State_code'].str.strip('()')\n",
    "\n",
    "df = df.drop(columns=['RegionFull', 'Unnamed: 2'])\n",
    "\n",
    "df_data = df[df['State'].notna()].copy()\n",
    "df_data = df_data.drop(columns=['Subregion', 'State'])\n",
    "\n",
    "# Now df_data has columns: Year (int), Subregion, State, plus any other data columns.\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_2_1_'></a>[Geographic insights](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the distinct States and subregions present within the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries in Melanesia:\n",
      "['Fiji' 'Papua New Guinea' 'Solomon Islands' 'Vanuatu' 'New Caledonia']\n",
      "\n",
      "Countries in Micronesia:\n",
      "['Kiribati' 'Marshall Islands' 'Micronesia (Federated States of)' 'Nauru'\n",
      " 'Palau']\n",
      "\n",
      "Countries in Polynesia:\n",
      "['Niue' 'Samoa' 'Tonga' 'Tuvalu' 'French Polynesia' 'Cook Islands']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_subregion_names = df_data['Subregion_name'].unique()\n",
    "\n",
    "for subregion in distinct_subregion_names:\n",
    "    print(f\"Countries in {subregion}:\")\n",
    "    countries = df_data[df_data['Subregion_name']\n",
    "                        == subregion]['State_name'].unique()\n",
    "    print(countries)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[Mapping key domains](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define first a list containing the seven key domains and create a mapping dictionary, `topic_ids`, that assigns each topic a unique numerical ID using an auto-incrementing pattern, starting from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Political Leadership and Regionalism': 1, 'People-Centred Development': 2, 'Peace and Security': 3, 'Resources and Economic Development': 4, 'Climate Change and Disasters': 5, 'Ocean and Environment': 6, 'Technology and Connectivity': 7}\n"
     ]
    }
   ],
   "source": [
    "class_list = [\n",
    "    \"Political Leadership and Regionalism\",\n",
    "    \"People-Centred Development\",\n",
    "    \"Peace and Security\",\n",
    "    \"Resources and Economic Development\",\n",
    "    \"Climate Change and Disasters\",\n",
    "    \"Ocean and Environment\",\n",
    "    \"Technology and Connectivity\"\n",
    "]\n",
    "\n",
    "# Build the dictionary with auto-incrementing IDs\n",
    "topic_ids = {topic: idx for idx, topic in enumerate(class_list, start=1)}\n",
    "\n",
    "print(topic_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_4_'></a>[Enrich with an indicator summary](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "An `indicator_summary` key-value pair has been generated with the help of an LLM on top of the initial [JSON containing the group structures](#looking-for-sentinels). It summarizes the whole content of the `(INDICATOR)` value.\n",
    "\n",
    "The purpose of this process is to enrich the dataset, `df_data`, by incorporating (manually in this case, but this could be automated) synthetically generated metadata that categorizes with **more granularity** the data based on their topics descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Begin by loading metadata from a JSON file, `groups_meta_augmented.json`, into a Python dictionary called `lookup`. Construct a DataFrame, `meta`, containing only the relevant fields: `Group_id`, `class_name`, and `indicator_summary`. \n",
    "2) Next, map each `class_name` to a numerical ID using the previously defined `topic_ids`. Finally, merge the `meta` DataFrame back into the original DataFrame, `df_data`, based on the `Group_id`, effectively **enriching** `df_data` with the additional summary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/groups_metadata_augmented.json') as f:\n",
    "    lookup = json.load(f)\n",
    "\n",
    "# 1) Build a small DataFrame from the JSON\n",
    "# Only need the fields: group_number, class, indicator_summary\n",
    "meta = pd.DataFrame([\n",
    "    {\n",
    "        \"Group_id\":          item[\"group_number\"],\n",
    "        \"class_name\":        item[\"class\"],\n",
    "        \"indicator_summary\": item[\"indicator_summary\"]\n",
    "    }\n",
    "    for item in lookup\n",
    "])\n",
    "\n",
    "meta[\"class_num\"] = meta[\"class_name\"].map(topic_ids)\n",
    "\n",
    "# 2) Merge back into original df\n",
    "df_data = df_data.merge(\n",
    "    meta,\n",
    "    on=\"Group_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_5_'></a>[Generate a complete group×state×year grid and detect missing records](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to ensure coverage of all subregion-state combinations across the identified groups and years. This process highlights any missing data points that ought to facilitate further investigation or remediation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Generate a master list of unique subregion-state combinations from `df_data` (this confirms no duplicates).\n",
    "2) All unique combinations of `Group_id` and `Year` are extracted to represent the available groups and years.\n",
    "3) **Create cartesian product:** a cartesian product is generated by merging the groups and master combinations, resulting in every possible combination of group-year and subregion-state.\n",
    "4) Detect missing rows: an *anti-join* is performed against the original dataset to find any combinations present in the cartesian product that are missing from the actual data, flags are identified through the `_merge` indicator.\n",
    "5) Extract missing keys: finally, isolate just the key columns from the missing data, thus allowing for targeted investigation of gaps in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Identify the master list of subregion↔state combos\n",
    "master = (\n",
    "    df_data[[\n",
    "        \"Subregion_code\",\n",
    "        \"Subregion_name\",\n",
    "        \"State_code\",\n",
    "        \"State_name\"\n",
    "    ]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Identify all the (Group_id, Year) combos\n",
    "groups = (\n",
    "    df_data[[\"Group_id\", \"Year\",\t\"class_name\",\t\"indicator_summary\",\t\"class_num\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 3) Make a cartesian product of every group×year with every master combo\n",
    "groups[\"_tmpkey\"] = 1\n",
    "master[\"_tmpkey\"] = 1\n",
    "\n",
    "full = (\n",
    "    groups\n",
    "    .merge(master, on=\"_tmpkey\")\n",
    "    .drop(columns=\"_tmpkey\")\n",
    ")\n",
    "\n",
    "# 4) Anti‐join full against the real data, but only on the key columns.\n",
    "#    *don’t* drop the Unnamed… cols yet, only use the keys to detect missing rows.\n",
    "merged = full.merge(\n",
    "    df_data,\n",
    "    on=[\n",
    "        \"Group_id\",\n",
    "        \"Subregion_code\", \"Subregion_name\",\n",
    "        \"State_code\", \"State_name\",\"Year\",\t\"class_name\",\t\"indicator_summary\",\t\"class_num\"\n",
    "    ],\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "missing = merged[merged[\"_merge\"] == \"left_only\"]\n",
    "\n",
    "# If key‐columns necessary\n",
    "missing_keys = missing[[\n",
    "    \"Group_id\",\n",
    "    \"Subregion_code\", \"Subregion_name\",\n",
    "    \"State_code\", \"State_name\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_5_1_'></a>[Investigate missing data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>class_name</th>\n",
       "      <th>indicator_summary</th>\n",
       "      <th>class_num</th>\n",
       "      <th>Subregion_code</th>\n",
       "      <th>Subregion_name</th>\n",
       "      <th>State_code</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>561024940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>572455900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>SB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>256630130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>VU</td>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>183972650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MIC</td>\n",
       "      <td>Micronesia</td>\n",
       "      <td>KI</td>\n",
       "      <td>Kiribati</td>\n",
       "      <td>90657960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group_id  Year                            class_name  \\\n",
       "0         1  2022  Political Leadership and Regionalism   \n",
       "1         1  2022  Political Leadership and Regionalism   \n",
       "2         1  2022  Political Leadership and Regionalism   \n",
       "3         1  2022  Political Leadership and Regionalism   \n",
       "4         1  2022  Political Leadership and Regionalism   \n",
       "\n",
       "       indicator_summary  class_num Subregion_code Subregion_name State_code  \\\n",
       "0  Total development aid          1            MEL      Melanesia         FJ   \n",
       "1  Total development aid          1            MEL      Melanesia         PG   \n",
       "2  Total development aid          1            MEL      Melanesia         SB   \n",
       "3  Total development aid          1            MEL      Melanesia         VU   \n",
       "4  Total development aid          1            MIC     Micronesia         KI   \n",
       "\n",
       "         State_name Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
       "0              Fiji  561024940        NaN        NaN        NaN        NaN   \n",
       "1  Papua New Guinea  572455900        NaN        NaN        NaN        NaN   \n",
       "2   Solomon Islands  256630130        NaN        NaN        NaN        NaN   \n",
       "3           Vanuatu  183972650        NaN        NaN        NaN        NaN   \n",
       "4          Kiribati   90657960        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 9 Unnamed: 10 _merge  \n",
       "0        NaN         NaN   both  \n",
       "1        NaN         NaN   both  \n",
       "2        NaN         NaN   both  \n",
       "3        NaN         NaN   both  \n",
       "4        NaN         NaN   both  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Section 2) The case of Group58 and Group18](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Group 58 - Transform wide-format-data to a long-format](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group 58** is special because its five education-related columns are stored as separate wide-format columns that need to be melted into rows (one per education level) and remapped into five new Group_id/indicator_summary values (581–585). All other groups are already in the desired long format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot Image](<img/education.png> \"Screenshot of an Excel spreadsheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing:\n",
    "\n",
    "1) Restructure the DataFrame by renaming columns and isolating rows for a specific group (Group 58), followed by *melting multiple education-related columns into a long format*. \n",
    "2) Additionally, assign new group IDs and summaries based on education levels, and merge this transformed data with the remaining dataset.\n",
    "\n",
    "Secundarily: Clean up the final DataFrame by dropping obsolete columns while making sure data types are correctly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 581 582 583 584 585]\n"
     ]
    }
   ],
   "source": [
    "# 1) Rename Unnamed:4 to values, drop Unnamed:10\n",
    "df_grp = merged.rename(columns={'Unnamed: 4': 'values'}).drop(\n",
    "    columns=['Unnamed: 10'])\n",
    "\n",
    "# 2) Split off the group 58 rows\n",
    "df58 = df_grp[df_grp['Group_id'] == 58].copy()\n",
    "df_rest = df_grp[df_grp['Group_id'] != 58].copy()\n",
    "\n",
    "# 3) Melt the five education columns\n",
    "education_cols = {\n",
    "    'Unnamed: 5': 'Pre-primary education',\n",
    "    'Unnamed: 6': 'Primary education',\n",
    "    'Unnamed: 7': 'Secondary education',\n",
    "    'Unnamed: 8': 'Lower secondary education',\n",
    "    'Unnamed: 9': 'Upper secondary education',\n",
    "}\n",
    "\n",
    "melted = (\n",
    "    df58\n",
    "    .melt(\n",
    "        id_vars=[c for c in df58.columns\n",
    "                 if c not in education_cols.keys()],\n",
    "        value_vars=list(education_cols.keys()),\n",
    "        var_name='education_col',\n",
    "        value_name='val'\n",
    "    )\n",
    "    # Drop any rows where the cell was NaN\n",
    "    # .dropna(subset=['values'])\n",
    ")\n",
    "\n",
    "# 4) Assign a new Group_id and indicator_summary based on the education level\n",
    "group_mapping = {\n",
    "    'Unnamed: 5': (581, 'Total development aid – Pre-primary'),\n",
    "    'Unnamed: 6': (582, 'Total development aid – Primary'),\n",
    "    'Unnamed: 7': (583, 'Total development aid – Secondary'),\n",
    "    'Unnamed: 8': (584, 'Total development aid – Lower secondary'),\n",
    "    'Unnamed: 9': (585, 'Total development aid – Upper secondary'),\n",
    "}\n",
    "\n",
    "\n",
    "def map_group(row):\n",
    "    gid, summary = group_mapping[row['education_col']]\n",
    "    row['Group_id'] = gid\n",
    "    row['indicator_summary'] = summary\n",
    "    return row\n",
    "\n",
    "\n",
    "melted = melted.apply(map_group, axis=1)\n",
    "\n",
    "# If need to reassign class_num etc., do that here.\n",
    "# e.g. melted['class_num'] = melted['Group_id'].map(my_classnum_map)\n",
    "\n",
    "# 5) Concatenate back together\n",
    "df_streamlined = pd.concat([df_rest, melted], ignore_index=True)\n",
    "\n",
    "# Now `df_final` has:\n",
    "# - all the original groups (except 58)\n",
    "# - for group 58 there are 5 new groups (581–585), one per education level,\n",
    "#   with their values transposed into rows\n",
    "# 1) merge the 'val' values into the 'values' column, preferring 'val' when it's not null\n",
    "df_streamlined['values'] = df_streamlined['val'].combine_first(\n",
    "    df_streamlined['values'])\n",
    "\n",
    "int_cols = ['Group_id', 'class_num', 'Year']\n",
    "float_cols = ['values']\n",
    "\n",
    "df_streamlined[int_cols] = df_streamlined[int_cols].astype(int)\n",
    "# df_streamlined[float_cols] = df_streamlined[float_cols].astype(float)\n",
    "\n",
    "# 3) Drop the unwanted columns\n",
    "cols_to_drop = [\n",
    "    'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7',\n",
    "    'Unnamed: 8', 'Unnamed: 9', '_merge',\n",
    "    'education_col', 'val'\n",
    "]\n",
    "df_streamlined = df_streamlined.drop(columns=cols_to_drop)\n",
    "df_streamlined['Raw_values'] = df_streamlined['values']\n",
    "\n",
    "print(df_streamlined.Group_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what we have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>class_name</th>\n",
       "      <th>indicator_summary</th>\n",
       "      <th>class_num</th>\n",
       "      <th>Subregion_code</th>\n",
       "      <th>Subregion_name</th>\n",
       "      <th>State_code</th>\n",
       "      <th>State_name</th>\n",
       "      <th>values</th>\n",
       "      <th>Raw_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>561024940</td>\n",
       "      <td>561024940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>572455900</td>\n",
       "      <td>572455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>SB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>256630130</td>\n",
       "      <td>256630130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group_id  Year                            class_name  \\\n",
       "0         1  2022  Political Leadership and Regionalism   \n",
       "1         1  2022  Political Leadership and Regionalism   \n",
       "2         1  2022  Political Leadership and Regionalism   \n",
       "\n",
       "       indicator_summary  class_num Subregion_code Subregion_name State_code  \\\n",
       "0  Total development aid          1            MEL      Melanesia         FJ   \n",
       "1  Total development aid          1            MEL      Melanesia         PG   \n",
       "2  Total development aid          1            MEL      Melanesia         SB   \n",
       "\n",
       "         State_name     values Raw_values  \n",
       "0              Fiji  561024940  561024940  \n",
       "1  Papua New Guinea  572455900  572455900  \n",
       "2   Solomon Islands  256630130  256630130  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_streamlined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! 👌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Group 18 - The case of inverse relationships](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group 18** is about the tuberculosis (TB) incidence rate. The higher it is, the worse the health outcome. This reflects an inverse relationship that deviates from the patterns observed in the rest of the dataset and will introduce noise into the synthetic scores computed later.\n",
    "\n",
    "- A reciprocal transformation adresses inverse relationships directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reciprocal transformation (only non-zero values)\n",
    "df_streamlined.loc[(df_streamlined['Group_id'] == 18) & (df_streamlined['values'] != 0), 'values'] = 1 / \\\n",
    "    df_streamlined.loc[(df_streamlined['Group_id'] == 18) & (\n",
    "        df_streamlined['values'] != 0), 'values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or drop group \n",
    "#df_streamlined = df_streamlined[df_streamlined['Group_id'] != 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Section 3) Prevalence filtering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many reports involving manual (international) data collection, reporting practices vary across different organizations. The result is a strong data imbalance among various groups, years, and key indicators. To make sense8 of this disparity, keep only the groups that have a sufficient number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Identify and filter out groups from the DataFrame `df_streamlined` that have more than 12 missing values in the values column. This means we keep only groups that are at least 25% complete (a topic group contains 16 distinct States).\n",
    "2) Keep only years **2022** and **2023** as they are the most complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 59 groups: [2, 3, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 30, 47, 50, 52, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 88, 95, 100, 102, 103, 104, 105, 106, 107, 109, 110, 583, 584, 585]\n"
     ]
    }
   ],
   "source": [
    "missings = df_streamlined.groupby('Group_id')['values'].apply(lambda s: s.isna().sum())\n",
    "\n",
    "# 1) Identify groups to drop\n",
    "to_drop = missings[missings > 12].index\n",
    "\n",
    "# 2) Filter them out\n",
    "df_clean = df_streamlined[~df_streamlined['Group_id'].isin(to_drop)].copy()\n",
    "# Keep only rows where Year is 2022 or 2023\n",
    "df_clean = df_clean[df_clean['Year'].isin([2022, 2023])]\n",
    "\n",
    "print(f\"Dropped {len(to_drop)} groups: {list(to_drop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Section 4) Scaling raw values](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to compute an indicator that effectively summarizes complex data into a single, interpretable value **(a synthesis score)**. To achieve this, it is crucial to address the challenge of handling mixed values across broad range scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check types and cast features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group_id              int64\n",
       "Year                  int64\n",
       "class_name           object\n",
       "indicator_summary    object\n",
       "class_num             int64\n",
       "Subregion_code       object\n",
       "Subregion_name       object\n",
       "State_code           object\n",
       "State_name           object\n",
       "values               object\n",
       "Raw_values           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float, set non-convertible to NaN\n",
    "df_clean['values'] = pd.to_numeric(df_clean['values'], errors='coerce')\n",
    "# Convert to float, set non-convertible to NaN\n",
    "df_clean['Raw_values'] = pd.to_numeric(df_clean['Raw_values'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply a proper tranformation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sigmoid_scale()` function normalizes a numeric column by first centering it around its group mean and scaling it by the group standard deviation. It then applies the sigmoid function to transform the normalized values into a **range between 0 and 1**. This is achieved through the expression:\n",
    "\n",
    "$\n",
    "\\frac{1}{1 + e^{-x}},\n",
    "$ \n",
    "\n",
    "where $ x $ is the normalized value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_scale(column):\n",
    "    # Normalize within group first to handle varying scales\n",
    "    normalized = (column - column.mean()) / column.std()\n",
    "    return 1 / (1 + np.exp(-normalized))\n",
    "\n",
    "df_clean['Scaled_Values'] = (\n",
    "    df_clean\n",
    "    .groupby('Group_id')['values']  # Group-wise scaling to not distort the analysis\n",
    "    .transform(sigmoid_scale)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main **advantage of sigmoid scaling** over a more common method like min-max scaling is that it does not map the minimum and maximum values to fixed endpoints (0 and 1), which prevents extreme values from being compressed at the bounds and reduces the disproportionate (non)influence of bottom and top values on downstream metrics, preserving relative differences and producing stable synthesis scores.\n",
    "\n",
    "- Without going too much into details, robust/standard/logarithm scaling are less convenient: these transforms do not by themselves produce fixed 0–1 bounds across groups, so an extra rescaling step is required to convert outputs to a [0,1] range (sigmoid scaling allows to keep a simple scoring workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>class_name</th>\n",
       "      <th>indicator_summary</th>\n",
       "      <th>class_num</th>\n",
       "      <th>Subregion_code</th>\n",
       "      <th>Subregion_name</th>\n",
       "      <th>State_code</th>\n",
       "      <th>State_name</th>\n",
       "      <th>values</th>\n",
       "      <th>Raw_values</th>\n",
       "      <th>Scaled_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>561024940.0000</td>\n",
       "      <td>561024940.0000</td>\n",
       "      <td>0.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>572455900.0000</td>\n",
       "      <td>572455900.0000</td>\n",
       "      <td>0.8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>1</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>SB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>256630130.0000</td>\n",
       "      <td>256630130.0000</td>\n",
       "      <td>0.5367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group_id  Year                            class_name  \\\n",
       "0         1  2022  Political Leadership and Regionalism   \n",
       "1         1  2022  Political Leadership and Regionalism   \n",
       "2         1  2022  Political Leadership and Regionalism   \n",
       "\n",
       "       indicator_summary  class_num Subregion_code Subregion_name State_code  \\\n",
       "0  Total development aid          1            MEL      Melanesia         FJ   \n",
       "1  Total development aid          1            MEL      Melanesia         PG   \n",
       "2  Total development aid          1            MEL      Melanesia         SB   \n",
       "\n",
       "         State_name         values     Raw_values  Scaled_Values  \n",
       "0              Fiji 561024940.0000 561024940.0000         0.8507  \n",
       "1  Papua New Guinea 572455900.0000 572455900.0000         0.8581  \n",
       "2   Solomon Islands 256630130.0000 256630130.0000         0.5367  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Section 5) Additional features](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Metrics for completeness and contributions/rankings](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is structured and clean. Let's add some analytical features. This includes metrics related to data completeness, group and class contributions, and ranking information across various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Missing values:**\n",
    "\n",
    "  1) Compute percent-missing values:\n",
    "    Calculates the percentage of missing `Raw_values` for each combination of `Year`, `class_name`, and `State_name`, storing it in: `pct_missing_values`. This helps identify groups with data gaps.\n",
    "\n",
    "  2) Flag missing entries:\n",
    "    A copy of `df_clean` is created as `df_final`, and a new column `Is_Missing` indicates whether each `Raw_values` entry is missing (1 if missing, 0 otherwise).\n",
    "  \n",
    "  3) Compute missing value shares:\n",
    "    The code calculates the count and percentage of missing values per `State` within each `Year` and `class_name`. This information is useful for assessing data quality by merging the missing counts back into `df_final`.\n",
    "\n",
    "- **Group weights:**\n",
    "\n",
    "  3) Compute total group values and item shares:\n",
    "    The code aggregates Scaled_Values to get `Total_Group_Value` for each `Group_id`, `Year`, and `class_name`. It then calculates the share of each item within its group as `Share_Item`, providing insight into the relative contribution of individual items to their respective groups.\n",
    "\n",
    "  4) Compute class values and related shares:\n",
    "    Similar aggregation is done at the class level to compute `Total_Class_Value`. The code calculates the share of each group within its class (`Share_Group`) and determines the overall contribution of items to their class (`value_contribution_to_class`) along with the share of each item within the class (`Share_Class`).\n",
    "\n",
    "- **Ranking:** \n",
    "  \n",
    "  5) Items and states:\n",
    "    Items are ranked within each `Group` and `Year` based on their `Scaled_Values` using `Item_Rank`. State-level totals are computed and ranked across `Year` and `class_name`, creating `State_rank_per_class`, allowing for comparative assessments of state performance.\n",
    "\n",
    "  6) Ranking subregions:\n",
    "    A similar ranking process is applied to subregions based on total scaled values, determining the `Subregion_Class_Rank`.\n",
    "\n",
    "- **Output:**\n",
    "\n",
    "  8) Final order of columns:\n",
    "    `df_final` is restructured to include only relevant columns in a specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_num</th>\n",
       "      <th>indicator_summary</th>\n",
       "      <th>Subregion_code</th>\n",
       "      <th>Subregion_name</th>\n",
       "      <th>State_code</th>\n",
       "      <th>State_name</th>\n",
       "      <th>Raw_values</th>\n",
       "      <th>Scaled_Values</th>\n",
       "      <th>value_contribution_to_class</th>\n",
       "      <th>State_rank_per_class</th>\n",
       "      <th>pct_missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>1</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>561024940.0000</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>1</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>572455900.0000</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Political Leadership and Regionalism</td>\n",
       "      <td>1</td>\n",
       "      <td>Total development aid</td>\n",
       "      <td>MEL</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>SB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>256630130.0000</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group_id  Year                            class_name  class_num  \\\n",
       "0         1  2022  Political Leadership and Regionalism          1   \n",
       "1         1  2022  Political Leadership and Regionalism          1   \n",
       "2         1  2022  Political Leadership and Regionalism          1   \n",
       "\n",
       "       indicator_summary Subregion_code Subregion_name State_code  \\\n",
       "0  Total development aid            MEL      Melanesia         FJ   \n",
       "1  Total development aid            MEL      Melanesia         PG   \n",
       "2  Total development aid            MEL      Melanesia         SB   \n",
       "\n",
       "         State_name     Raw_values  Scaled_Values  \\\n",
       "0              Fiji 561024940.0000         0.8507   \n",
       "1  Papua New Guinea 572455900.0000         0.8581   \n",
       "2   Solomon Islands 256630130.0000         0.5367   \n",
       "\n",
       "   value_contribution_to_class  State_rank_per_class  pct_missing_values  \n",
       "0                       0.0305                     6              0.0000  \n",
       "1                       0.0308                    12              0.0000  \n",
       "2                       0.0193                    13              0.0000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute percent‐missing per Year, class_name, State_name\n",
    "df_clean['pct_missing_values'] = (\n",
    "    df_clean\n",
    "    .groupby(['Year', 'class_name', 'State_name'])['Raw_values']\n",
    "    .transform(lambda col: col.isna().mean() * 100)\n",
    ")\n",
    "# 1) Copy & flag missing\n",
    "df_final = df_clean.copy()\n",
    "df_final['Is_Missing'] = df_final['Raw_values'].isna().astype(int)\n",
    "\n",
    "# 2) Compute Total_Group_Value and Share_Item\n",
    "group_totals = (\n",
    "    df_final\n",
    "    .groupby(['Group_id', 'Year', 'class_name'])['Scaled_Values']\n",
    "    .sum()\n",
    "    .reset_index(name='Total_Group_Value')\n",
    ")\n",
    "df_final = df_final.merge(\n",
    "    group_totals, on=['Group_id', 'Year', 'class_name'], how='left')\n",
    "df_final['Share_Item'] = df_final['Scaled_Values'] / \\\n",
    "    df_final['Total_Group_Value']\n",
    "\n",
    "# 3) Compute Total_Class_Value and related shares\n",
    "class_totals = (\n",
    "    df_final\n",
    "    .groupby(['Year', 'class_name'])['Scaled_Values']\n",
    "    .sum()\n",
    "    .reset_index(name='Total_Class_Value')\n",
    ")\n",
    "df_final = df_final.merge(class_totals, on=['Year', 'class_name'], how='left')\n",
    "df_final['Share_Group'] = df_final['Total_Group_Value'] / \\\n",
    "    df_final['Total_Class_Value']\n",
    "df_final['value_contribution_to_class'] = df_final['Share_Item'] * \\\n",
    "    df_final['Share_Group']\n",
    "df_final['Share_Class'] = df_final['Scaled_Values'] / \\\n",
    "    df_final['Total_Class_Value']\n",
    "\n",
    "# 4) Rank items within each (Group × Year)\n",
    "df_final['Item_Rank'] = (\n",
    "    df_final\n",
    "    .groupby(['Group_id', 'Year'])['Scaled_Values']\n",
    "    .rank(ascending=False, method='min')\n",
    "    .astype(\"Int64\")\n",
    ")\n",
    "\n",
    "# 5) Rank each STATE by total Scaled_Values within (Year × class_name)\n",
    "state_totals = (\n",
    "    df_final\n",
    "    .groupby(['Year', 'class_name', 'State_code', 'State_name'])['Scaled_Values']\n",
    "    .sum()\n",
    "    .reset_index(name='State_Class_Total')\n",
    ")\n",
    "state_totals['State_rank_per_class'] = (\n",
    "    state_totals\n",
    "    .groupby(['Year', 'class_name'])['State_Class_Total']\n",
    "    .rank(ascending=False, method='min')\n",
    "    .astype(\"Int64\")\n",
    ")\n",
    "df_final = df_final.merge(\n",
    "    state_totals[\n",
    "        ['Year', 'class_name', 'State_code',\n",
    "            'State_Class_Total', 'State_rank_per_class']\n",
    "    ],\n",
    "    on=['Year', 'class_name', 'State_code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 6) Rank each SUBREGION by total Scaled_Values within (Year × class_name)\n",
    "subregion_totals = (\n",
    "    df_final\n",
    "    .groupby(['Year', 'class_name', 'Subregion_code', 'Subregion_name'])['Scaled_Values']\n",
    "    .sum()\n",
    "    .reset_index(name='Subregion_Class_Total')\n",
    ")\n",
    "subregion_totals['Subregion_Class_Rank'] = (\n",
    "    subregion_totals\n",
    "    .groupby(['Year', 'class_name'])['Subregion_Class_Total']\n",
    "    .rank(ascending=False, method='min')\n",
    "    .astype(\"Int64\")\n",
    ")\n",
    "df_final = df_final.merge(\n",
    "    subregion_totals[\n",
    "        ['Year', 'class_name', 'Subregion_code',\n",
    "            'Subregion_Class_Total', 'Subregion_Class_Rank']\n",
    "    ],\n",
    "    on=['Year', 'class_name', 'Subregion_code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 7) Compute missing‐value shares per state within each (Year × class_name)\n",
    "state_missing = (\n",
    "    df_final\n",
    "    .groupby(['Year', 'class_name', 'State_code', 'State_name'])['Is_Missing']\n",
    "    .sum()\n",
    "    .reset_index(name='State_Missing_Count')\n",
    ")\n",
    "class_missing = (\n",
    "    df_final\n",
    "    .groupby(['Year', 'class_name'])['Is_Missing']\n",
    "    .sum()\n",
    "    .reset_index(name='Class_Missing_Count')\n",
    ")\n",
    "state_missing = state_missing.merge(\n",
    "    class_missing, on=['Year', 'class_name'], how='left'\n",
    ")\n",
    "state_missing['State_Missing_Pct'] = (\n",
    "    100 * state_missing['State_Missing_Count']\n",
    "    / state_missing['Class_Missing_Count']\n",
    ").fillna(0)\n",
    "\n",
    "df_final = df_final.merge(\n",
    "    state_missing[\n",
    "        ['Year', 'class_name', 'State_code',\n",
    "         'State_Missing_Count', 'Class_Missing_Count', 'State_Missing_Pct']\n",
    "    ],\n",
    "    on=['Year', 'class_name', 'State_code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 8) Final column ordering\n",
    "final_cols = [\n",
    "    'Group_id', 'Year', 'class_name', 'class_num', 'indicator_summary',\n",
    "    'Subregion_code', 'Subregion_name', 'State_code', 'State_name',\n",
    "    'Raw_values', 'Scaled_Values', 'value_contribution_to_class', 'State_rank_per_class',\n",
    "    'pct_missing_values'\n",
    "]\n",
    "df_final = df_final[final_cols]\n",
    "\n",
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_2_'></a>[Interactive report about data quality](#toc0_)\n",
    "\n",
    "Check missingness and disparity indicators accross the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and store the top N entities (States and Subregions) for:\n",
    "\n",
    "- Most missing values\n",
    "- Largest disparities in values\n",
    "- Most balanced values (smallest disparities)\n",
    "\n",
    "**Metrics calculation:** the `compute_group_metrics()` function computes metrics for each combination of `class_name`, `Year`, and a specified grouping column. It calculates the number of **missing values**, **maximum** and **minimum** values, and their **disparity** (the difference between maximum and minimum).\n",
    "\n",
    "**Top N Analysis:** the `top_n_within()` function retrieves the top N entries for each combination of `class_name` and `Year`, based on specified criteria; either the number of missing values or the (large/small) disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d715c724f464632aba5d53325d0917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(ToggleButtons(options=(('State', 'State'), ('Subregion', 'Subregion')), value='State'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eef67969944e92a4cab82e4fc9f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid gray', border_left='1px solid gray', border_right='1px solid gra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VALUE_COL = 'Scaled_Values'\n",
    "DF = df_final\n",
    "\n",
    "\n",
    "def compute_group_metrics(df, group_col, value_col):\n",
    "    grouped = df.groupby(['class_name', 'Year', group_col])[value_col]\n",
    "    metrics = grouped.agg(\n",
    "        missing_count=lambda s: int(s.isna().sum()),\n",
    "        max_val=lambda s: np.nanmax(\n",
    "            s.values) if s.dropna().size > 0 else np.nan,\n",
    "        min_val=lambda s: np.nanmin(\n",
    "            s.values) if s.dropna().size > 0 else np.nan\n",
    "    ).reset_index()\n",
    "    metrics['disparity'] = metrics['max_val'] - metrics['min_val']\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def top_n_within(groups_df, by, n=5, ascending=False):\n",
    "    sorted_df = groups_df.sort_values(by=by, ascending=ascending)\n",
    "    return sorted_df.groupby(['class_name', 'Year']).head(n)\n",
    "\n",
    "\n",
    "# Pre-compute metrics for both granularities\n",
    "country_metrics = compute_group_metrics(DF, 'State_name', VALUE_COL)\n",
    "subregion_metrics = compute_group_metrics(DF, 'Subregion_name', VALUE_COL)\n",
    "\n",
    "# --- Widget controls ---\n",
    "granularity_w = widgets.ToggleButtons(\n",
    "    options=[('State', 'State'), ('Subregion', 'Subregion')],\n",
    "    value='State'\n",
    "    \n",
    ")\n",
    "\n",
    "# Dynamic options for class_name and Year derived from data\n",
    "class_options = sorted(DF['class_name'].dropna().unique().tolist())\n",
    "year_options = sorted(DF['Year'].dropna().unique().tolist())\n",
    "\n",
    "class_w = widgets.Dropdown(options=class_options, description='class_name:')\n",
    "year_w = widgets.Dropdown(options=year_options, description='Year:')\n",
    "\n",
    "top_n_w = widgets.IntSlider(value=5, min=1, max=20,\n",
    "                            step=1, description='Top N:')\n",
    "\n",
    "# --- Display / update logic ---\n",
    "out = widgets.Output(layout={'border': '1px solid gray'})\n",
    "\n",
    "\n",
    "def render_report(granularity, class_name, year, top_n):\n",
    "    out.clear_output()\n",
    "    # Choose metrics df\n",
    "    if granularity == 'State':\n",
    "        metrics_df = country_metrics\n",
    "        group_col = 'State_name'\n",
    "    else:\n",
    "        metrics_df = subregion_metrics\n",
    "        group_col = 'Subregion_name'\n",
    "    # Filter for selected class_name and year\n",
    "    filt = (metrics_df['class_name'] == class_name) & (\n",
    "        metrics_df['Year'] == year)\n",
    "    df_sel = metrics_df.loc[filt].copy()\n",
    "    if df_sel.empty:\n",
    "        with out:\n",
    "            display(HTML(\n",
    "                f\"<b>No data for class_name={class_name}, Year={year}, granularity={granularity}.</b>\"))\n",
    "        return\n",
    "\n",
    "    # Compute top lists\n",
    "    top_missing = df_sel.sort_values(\n",
    "        by='missing_count', ascending=False).head(top_n)\n",
    "    top_disparity = df_sel.sort_values(\n",
    "        by='disparity', ascending=False).head(top_n)\n",
    "    top_balanced = df_sel.sort_values(\n",
    "        by='disparity', ascending=True).head(top_n)\n",
    "\n",
    "    # Add rank columns for clarity\n",
    "    top_missing = top_missing.assign(rank_missing=range(\n",
    "        1, len(top_missing)+1)).set_index('rank_missing')\n",
    "    top_disparity = top_disparity.assign(rank_disparity=range(\n",
    "        1, len(top_disparity)+1)).set_index('rank_disparity')\n",
    "    top_balanced = top_balanced.assign(rank_balanced=range(\n",
    "        1, len(top_balanced)+1)).set_index('rank_balanced')\n",
    "\n",
    "    with out:\n",
    "        display(HTML(\n",
    "            f\"<h3>Granularity: {granularity} — class_name: {class_name} — Year: {year}</h3>\"))\n",
    "        display(HTML(\"<b>Top by missing_count (most missing)</b>\"))\n",
    "        display(top_missing[[group_col, 'missing_count',\n",
    "                'max_val', 'min_val', 'disparity']])\n",
    "        display(HTML(\"<b>Top by disparity (largest disparity)</b>\"))\n",
    "        display(top_disparity[[group_col, 'missing_count',\n",
    "                'max_val', 'min_val', 'disparity']])\n",
    "        display(HTML(\"<b>Top by disparity (smallest = most balanced)</b>\"))\n",
    "        display(top_balanced[[group_col, 'missing_count',\n",
    "                'max_val', 'min_val', 'disparity']])\n",
    "\n",
    "# Wire up interactions\n",
    "def on_change(change):\n",
    "    render_report(granularity_w.value, class_w.value,\n",
    "                  year_w.value, top_n_w.value)\n",
    "\n",
    "\n",
    "granularity_w.observe(on_change, names='value')\n",
    "class_w.observe(on_change, names='value')\n",
    "year_w.observe(on_change, names='value')\n",
    "top_n_w.observe(on_change, names='value')\n",
    "\n",
    "controls = widgets.HBox([granularity_w, class_w, year_w, top_n_w])\n",
    "display(controls)\n",
    "display(out)\n",
    "\n",
    "# Render\n",
    "render_report(granularity_w.value, class_w.value, year_w.value, top_n_w.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_3_'></a>[Export data to JSON](#toc0_)\n",
    "\n",
    "The processed data is now prepared for its integration with the [dataWave app](https://github.com/brooks-code/blue-pacific-dataviz) backend.\n",
    "\n",
    "![Demo Image](<img/data_pearls.gif> \"Screenshot of the dataWave app.\")\n",
    "\n",
    "[Live demo](https://brooks-code.github.io/blue-pacific-dataviz/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns = df_final.columns.str.lower()\n",
    "\n",
    "# export to JSON file\n",
    "df_final.to_json('dataWave.json', orient='records', lines=False, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in the **Summer of 25 [🌠](https://en.wikipedia.org/wiki/Perseids)** - (kudos). \n",
    "\n",
    "To the moon 🌑 (and back).\n",
    "\n",
    "A notebook by [brk](github.com/brooks-code). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
